"""–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è –∏ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö —Ñ–∞–π–ª–æ–≤ –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏.

–°—Ü–µ–Ω–∞—Ä–∏–π –ø–æ–º–æ–≥–∞–µ—Ç –≤—ã—è–≤–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏ —Å–∫—Ä–∏–ø—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
–¥—É–±–ª–∏—Ä—É—é—Ç –¥—Ä—É–≥ –¥—Ä—É–≥–∞ –∏–ª–∏ –æ—Ç–Ω–æ—Å—è—Ç—Å—è –∫ —É—Å—Ç–∞—Ä–µ–≤—à–∏–º ¬´–≥–æ—Ä—è—á–∏–º¬ª —Ñ–∏–∫—Å–∞–º.
–û—Ç—á—ë—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ —Ä–∞–º–∫–∞—Ö —Ä–∞–∑–¥–µ–ª–∞ "Cleanup & Legacy Removal" –≥–µ–Ω–µ—Ä–∞–ª—å–Ω–æ–≥–æ
–ø–ª–∞–Ω–∞ –º–æ–¥–µ—Ä–Ω–∏–∑–∞—Ü–∏–∏.
"""

from __future__ import annotations

import argparse
import datetime as dt
import json
import re
from dataclasses import dataclass
from pathlib import Path
from typing import Iterable, Sequence

__all__ = [
    "AuditCandidate",
    "scan_redundant_files",
    "build_markdown_report",
    "main",
]

_ROOT_KEYWORDS = (
    "report",
    "summary",
    "fix",
    "checklist",
    "guide",
    "status",
    "final",
    "audit",
)
_SCRIPT_KEYWORDS = (
    "fix",
    "legacy",
    "backup",
    "old",
)
_IGNORED_DIRS = {
    ".git",
    ".github",
    "__pycache__",
    "build",
    "dist",
    "logs",
    "venv",
    "env",
    ".venv",
}
_DOC_SUFFIXES = {".md", ".txt"}
_SCRIPT_SUFFIXES = {".py", ".ps1", ".bat"}


@dataclass(slots=True)
class AuditCandidate:
    """–û–ø–∏—Å–∞–Ω–∏–µ —Ñ–∞–π–ª–∞, –∫–æ—Ç–æ—Ä—ã–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ —Å–ª–µ–¥—É–µ—Ç –ø–µ—Ä–µ–º–µ—Å—Ç–∏—Ç—å –≤ –∞—Ä—Ö–∏–≤."""

    path: Path
    reasons: list[str]
    size_bytes: int
    modified_at: dt.datetime

    def to_dict(self, root: Path) -> dict[str, object]:
        """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –∫ —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º–æ–º—É –≤–∏–¥—É."""

        return {
            "path": str(self.path.relative_to(root)),
            "reasons": list(self.reasons),
            "size_bytes": self.size_bytes,
            "modified_at": self.modified_at.isoformat(timespec="seconds"),
        }


def _iter_project_files(root: Path) -> Iterable[Path]:
    for path in root.rglob("*"):
        if not path.is_file():
            continue
        if any(part in _IGNORED_DIRS for part in path.parts):
            continue
        yield path


def _normalise_name(path: Path) -> str:
    base = path.stem.lower()
    base = re.sub(r"v\d+(?:[._-]\d+)*", "", base)
    base = re.sub(r"\d+", "", base)
    base = re.sub(r"[^a-z0-9]+", "", base)
    return base


def _collect_keyword_reasons(path: Path, relative: Path) -> list[str]:
    reasons: list[str] = []
    depth = len(relative.parts)
    lower_name = path.stem.lower()

    if depth == 1 and path.suffix in _DOC_SUFFIXES:
        for keyword in _ROOT_KEYWORDS:
            if keyword in lower_name:
                reasons.append(
                    f"–ù–∞–∑–≤–∞–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ '{keyword}' ‚Äî –≤–µ—Ä–æ—è—Ç–Ω—ã–π —Å–ª—É–∂–µ–±–Ω—ã–π –æ—Ç—á—ë—Ç"
                )
                break

    if depth == 1 and path.suffix in _SCRIPT_SUFFIXES:
        for keyword in _SCRIPT_KEYWORDS:
            if keyword in lower_name:
                reasons.append(
                    "–°—Ü–µ–Ω–∞—Ä–∏–π —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω –≤ –∫–æ—Ä–Ω–µ –∏ –≤—ã–≥–ª—è–¥–∏—Ç –∫–∞–∫ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∏–∫—Å"
                )
                break

    return reasons


def scan_redundant_files(root: Path) -> list[AuditCandidate]:
    """–°–∫–∞–Ω–∏—Ä—É–µ—Ç —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –≤ –ø–æ–∏—Å–∫–µ –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è –∏–ª–∏ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö —Ñ–∞–π–ª–æ–≤."""

    root = root.resolve()
    documents: list[Path] = []
    candidates: dict[Path, AuditCandidate] = {}

    for file_path in _iter_project_files(root):
        relative = file_path.relative_to(root)
        reasons = _collect_keyword_reasons(file_path, relative)

        if file_path.suffix in _DOC_SUFFIXES and len(relative.parts) == 1:
            documents.append(file_path)

        if reasons:
            candidate = AuditCandidate(
                path=file_path,
                reasons=reasons,
                size_bytes=file_path.stat().st_size,
                modified_at=dt.datetime.fromtimestamp(
                    file_path.stat().st_mtime, tz=dt.timezone.utc
                ),
            )
            candidates[file_path] = candidate

    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Ö–æ–∂–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ä–µ–¥–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤–µ—Ä—Ö–Ω–µ–≥–æ —É—Ä–æ–≤–Ω—è.
    groups: dict[str, list[Path]] = {}
    for document in documents:
        key = _normalise_name(document)
        groups.setdefault(key, []).append(document)

    for group in groups.values():
        if len(group) < 2:
            continue
        reason = "–ù–∞–π–¥–µ–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –ø–æ—Ö–æ–∂–∏–º –Ω–∞–∑–≤–∞–Ω–∏–µ–º ‚Äî –≤–æ–∑–º–æ–∂–Ω–æ, –∏—Ö —Å—Ç–æ–∏—Ç –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å"
        for path in group:
            candidate = candidates.get(path)
            if candidate is None:
                candidate = AuditCandidate(
                    path=path,
                    reasons=[reason],
                    size_bytes=path.stat().st_size,
                    modified_at=dt.datetime.fromtimestamp(
                        path.stat().st_mtime, tz=dt.timezone.utc
                    ),
                )
                candidates[path] = candidate
            elif reason not in candidate.reasons:
                candidate.reasons.append(reason)

    return sorted(candidates.values(), key=lambda cand: cand.path)


def build_markdown_report(candidates: Sequence[AuditCandidate], root: Path) -> str:
    """–°—Ç—Ä–æ–∏—Ç Markdown-–æ—Ç—á—ë—Ç –ø–æ –Ω–∞–π–¥–µ–Ω–Ω—ã–º –∫–∞–Ω–¥–∏–¥–∞—Ç–∞–º."""

    lines: list[str] = []
    lines.append("# üì¶ –ê—É–¥–∏—Ç –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –∏–∑–±—ã—Ç–æ—á–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤")
    lines.append("")
    lines.append(
        f"–î–∞—Ç–∞ –æ—Ç—á—ë—Ç–∞: {dt.datetime.now(tz=dt.timezone.utc).isoformat(timespec='seconds')}"
    )
    lines.append("")

    if not candidates:
        lines.append("‚úÖ –ü–æ–¥—Ö–æ–¥—è—â–∏—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
        return "\n".join(lines)

    lines.append(
        "–ù–∏–∂–µ –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω—ã —Ñ–∞–π–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —ç–≤—Ä–∏—Å—Ç–∏–∫–∞–º –ø—Ä–æ–≥—Ä–∞–º–º—ã –æ—á–∏—Å—Ç–∫–∏."
        "\n"
        "–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∏—Ö –∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø–µ—Ä–µ–Ω–µ—Å—Ç–∏ –≤ –∞—Ä—Ö–∏–≤ `archive/`."
    )
    lines.append("")

    for candidate in candidates:
        rel_path = candidate.path.relative_to(root)
        lines.append(f"## {rel_path}")
        lines.append("")
        lines.append(f"- –†–∞–∑–º–µ—Ä: {candidate.size_bytes} –±–∞–π—Ç")
        lines.append(
            "- –î–∞—Ç–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è: "
            f"{candidate.modified_at.astimezone(dt.timezone.utc).isoformat(timespec='seconds')}"
        )
        lines.append("- –ü—Ä–∏—á–∏–Ω—ã:")
        for reason in candidate.reasons:
            lines.append(f"  - {reason}")
        lines.append("")

    return "\n".join(lines)


def _build_arg_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(
        description="–ü–æ–∏—Å–∫ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –∏–∑–±—ã—Ç–æ—á–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏"
    )
    parser.add_argument(
        "--root",
        type=Path,
        default=Path.cwd(),
        help="–ö–æ—Ä–Ω–µ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ø—Ä–æ–µ–∫—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ç–µ–∫—É—â–∞—è)",
    )
    parser.add_argument(
        "--output",
        type=Path,
        help="–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç—á—ë—Ç–∞ (Markdown –∏–ª–∏ JSON)",
    )
    parser.add_argument(
        "--format",
        choices=("md", "json"),
        default="md",
        help="–§–æ—Ä–º–∞—Ç –æ—Ç—á—ë—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é Markdown)",
    )
    return parser


def main(argv: Sequence[str] | None = None) -> int:
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è CLI."""

    parser = _build_arg_parser()
    args = parser.parse_args(argv)

    root = args.root.resolve()
    candidates = scan_redundant_files(root)

    if args.output is None:
        report = build_markdown_report(candidates, root)
        print(report)
        return 0

    output_path: Path = args.output
    output_path.parent.mkdir(parents=True, exist_ok=True)

    if args.format == "md":
        report = build_markdown_report(candidates, root)
        output_path.write_text(report, encoding="utf-8")
    else:
        payload = [candidate.to_dict(root) for candidate in candidates]
        output_path.write_text(
            json.dumps(payload, ensure_ascii=False, indent=2), encoding="utf-8"
        )

    return 0


if __name__ == "__main__":  # pragma: no cover - CLI –∑–∞–ø—É—Å–∫
    raise SystemExit(main())
