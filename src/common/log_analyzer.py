# -*- coding: utf-8 -*-
"""
–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ª–æ–≥–æ–≤ PneumoStabSim
–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ —Ç–∏–ø—ã –∞–Ω–∞–ª–∏–∑–æ–≤ –≤ –µ–¥–∏–Ω—É—é —Å–∏—Å—Ç–µ–º—É
"""

from pathlib import Path
from typing import Dict, List, Optional, Tuple
from datetime import datetime
import json
import re
from collections import defaultdict, Counter


class LogAnalysisResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –ª–æ–≥–æ–≤"""
    
    def __init__(self):
        self.errors: List[str] = []
        self.warnings: List[str] = []
        self.info: List[str] = []
        self.metrics: Dict[str, float] = {}
        self.recommendations: List[str] = []
        self.status: str = "unknown"  # ok, warning, error
    
    def is_ok(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –≤—Å—ë –ª–∏ –≤ –ø–æ—Ä—è–¥–∫–µ"""
        return len(self.errors) == 0 and self.status != "error"
    
    def add_error(self, message: str):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –æ—à–∏–±–∫—É"""
        self.errors.append(message)
        self.status = "error"
    
    def add_warning(self, message: str):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ"""
        self.warnings.append(message)
        if self.status != "error":
            self.status = "warning"
    
    def add_info(self, message: str):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é"""
        self.info.append(message)
        if self.status == "unknown":
            self.status = "ok"
    
    def add_metric(self, name: str, value: float):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –º–µ—Ç—Ä–∏–∫—É"""
        self.metrics[name] = value
    
    def add_recommendation(self, message: str):
        """–î–æ–±–∞–≤–ª—è–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é"""
        self.recommendations.append(message)
    # --- NEW helpers for structured errors ---
    def add_collapsed_errors(self, errors: List[str]):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –Ω–∞–±–æ—Ä –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –æ—à–∏–±–æ–∫ (—É–Ω–∏–∫–∞–ª–∏–∑–∏—Ä—É—è –ø–æ —Å–æ–æ–±—â–µ–Ω–∏—é)."""
        for e in errors:
            self.add_error(e)


class UnifiedLogAnalyzer:
    """–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ –ª–æ–≥–æ–≤"""
    
    def __init__(self, logs_dir: Path = Path("logs")):
        self.logs_dir = logs_dir
        self.results: Dict[str, LogAnalysisResult] = {}
    
    def analyze_all(self) -> Dict[str, LogAnalysisResult]:
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö –ª–æ–≥–æ–≤"""
        
        # –û—Å–Ω–æ–≤–Ω–æ–π –ª–æ–≥
        self.results['main'] = self._analyze_main_log()
        
        # Graphics –ª–æ–≥–∏
        self.results['graphics'] = self._analyze_graphics_logs()
        
        # IBL –ª–æ–≥–∏
        self.results['ibl'] = self._analyze_ibl_logs()
        
        # Event –ª–æ–≥–∏ (Python‚ÜîQML)
        self.results['events'] = self._analyze_event_logs()
        
        # –û–±—â–∏–π —Å—Ç–∞—Ç—É—Å
        self.results['summary'] = self._generate_summary()
        
        return self.results
    
    def _analyze_main_log(self) -> LogAnalysisResult:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ—Å–Ω–æ–≤–Ω–æ–π –ª–æ–≥ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
        result = LogAnalysisResult()
        
        run_log = self.logs_dir / "run.log"
        if not run_log.exists():
            result.add_error("run.log –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return result
        
        try:
            with open(run_log, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            errors = [line for line in lines if 'ERROR' in line or 'CRITICAL' in line]
            warnings = [line for line in lines if 'WARNING' in line]
            
            result.add_metric('total_lines', len(lines))
            result.add_metric('errors', len(errors))
            result.add_metric('warnings', len(warnings))
            
            if errors:
                # –ü–æ–ª–Ω—ã–π —Ä–∞–∑–±–æ—Ä –æ—à–∏–±–æ–∫ —Å –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–æ–π –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –±–µ–∑ —Ç–∞–π–º—Å—Ç–µ–º–ø–æ–≤
                norm_errors: Dict[str, List[str]] = defaultdict(list)
                ts_re = re.compile(r'^\s*\d{4}-\d{2}-\d{2}[^ ]*\s+')
                for line in errors:
                    base = ts_re.sub('', line).strip()
                    # –£—Ä–µ–∑–∞–µ–º –ø—É—Ç—å –≤–Ω—É—Ç—Ä–∏ traceback —Å—Ç—Ä–æ–∫ –¥–æ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞ –¥–ª—è –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
                    base_short = re.sub(r'File "([^"]+)"', lambda m: f"File '{Path(m.group(1)).name}'", base)
                    norm_errors[base_short].append(line.strip())
    
                # –î–æ–±–∞–≤–ª—è–µ–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å—Ç—Ä–æ–∫—É
                result.add_error(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(errors)} –æ—à–∏–±–æ–∫ –≤ run.log (—É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: {len(norm_errors)})")
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –≤—Ö–æ–∂–¥–µ–Ω–∏–π
                for msg, lines_same in sorted(norm_errors.items(), key=lambda x: len(x[1]), reverse=True):
                    count = len(lines_same)
                    prefix = 'CRITICAL' if 'CRITICAL' in msg or 'FATAL' in msg else 'ERROR'
                    result.add_error(f"[{prefix}] {count}√ó {msg}")
                # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–æ—Ç–∫–∏–π —Å–æ–≤–µ—Ç –µ—Å–ª–∏ –º–Ω–æ–≥–æ —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤
                if len(norm_errors) > 5:
                    result.add_recommendation("–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –æ—à–∏–±–æ–∫ ‚Äî –Ω–∞—á–Ω–∏—Ç–µ —Å –ø–µ—Ä–≤–æ–π –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –ø–æ–≤—Ç–æ—Ä–æ–≤.")
            
            if warnings:
                result.add_warning(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(warnings)} –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π")
                if len(warnings) > 10:
                    result.add_recommendation("–ú–Ω–æ–≥–æ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π - –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é")
            
            if not errors and not warnings:
                result.add_info("–û—Å–Ω–æ–≤–Ω–æ–π –ª–æ–≥ —á–∏—Å—Ç—ã–π - –æ—à–∏–±–æ–∫ –Ω–µ—Ç")
            
            # –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–∏ —Ä–∞–±–æ—Ç—ã
            startup_time = None
            shutdown_time = None
            
            for line in lines:
                if 'START RUN' in line:
                    match = re.search(r'\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}', line)
                    if match:
                        startup_time = match.group(0)
                elif 'END RUN' in line:
                    match = re.search(r'\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}', line)
                    if match:
                        shutdown_time = match.group(0)
            
            if startup_time and shutdown_time:
                try:
                    start = datetime.fromisoformat(startup_time)
                    end = datetime.fromisoformat(shutdown_time)
                    duration = (end - start).total_seconds()
                    result.add_metric('runtime_seconds', duration)
                    result.add_info(f"–í—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã: {duration:.1f}s")
                except:
                    pass
            
        except Exception as e:
            result.add_error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ run.log: {e}")
        
        return result
    
    def _analyze_graphics_logs(self) -> LogAnalysisResult:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ª–æ–≥–∏ –≥—Ä–∞—Ñ–∏–∫–∏"""
        result = LogAnalysisResult()
        
        graphics_dir = self.logs_dir / "graphics"
        if not graphics_dir.exists():
            result.add_warning("–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è graphics –ª–æ–≥–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return result
        
        # –ù–∞—Ö–æ–¥–∏–º –ø–æ—Å–ª–µ–¥–Ω–∏–π session –ª–æ–≥
        session_logs = sorted(graphics_dir.glob("session_*.jsonl"), key=lambda p: p.stat().st_mtime, reverse=True)
        
        if not session_logs:
            result.add_warning("–ù–µ—Ç session –ª–æ–≥–æ–≤ –≥—Ä–∞—Ñ–∏–∫–∏")
            return result
        
        latest_session = session_logs[0]
        
        try:
            events = []
            with open(latest_session, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        try:
                            events.append(json.loads(line))
                        except json.JSONDecodeError:
                            continue
            
            # –ê–Ω–∞–ª–∏–∑ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
            total_events = len([e for e in events if e.get('event_type') in ('parameter_change', 'parameter_update')])
            synced_events = len([e for e in events if e.get('applied_to_qml', False)])
            failed_events = len([e for e in events if e.get('error')])
            
            result.add_metric('graphics_total_events', total_events)
            result.add_metric('graphics_synced', synced_events)
            result.add_metric('graphics_failed', failed_events)
            
            if total_events > 0:
                sync_rate = (synced_events / total_events) * 100
                result.add_metric('graphics_sync_rate', sync_rate)
                
                if sync_rate >= 95:
                    result.add_info(f"–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –≥—Ä–∞—Ñ–∏–∫–∏: {sync_rate:.1f}% (–æ—Ç–ª–∏—á–Ω–æ)")
                elif sync_rate >= 80:
                    result.add_warning(f"–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –≥—Ä–∞—Ñ–∏–∫–∏: {sync_rate:.1f}% (–ø—Ä–∏–µ–º–ª–µ–º–æ)")
                    result.add_recommendation("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ QML —Ñ—É–Ω–∫—Ü–∏–∏ applyXxxUpdates()")
                else:
                    result.add_error(f"–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –≥—Ä–∞—Ñ–∏–∫–∏: {sync_rate:.1f}% (–∫—Ä–∏—Ç–∏—á–Ω–æ –Ω–∏–∑–∫–∞—è)")
                    result.add_recommendation("–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ - –ø—Ä–æ–≤–µ—Ä—å—Ç–µ Python‚ÜîQML –º–æ—Å—Ç")
            
            # –ê–Ω–∞–ª–∏–∑ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
            categories = Counter(e.get('category', 'unknown') for e in events if e.get('category'))
            if categories:
                result.add_info(f"–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π: {dict(categories)}")
            
            # –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –æ—à–∏–±–∫–∏ QML sync (error –ø–æ–ª—è)
            error_events = [e for e in events if e.get('error')]
            if error_events:
                grouped = defaultdict(list)
                for ev in error_events:
                    key = ev.get('error')
                    grouped[key].append(ev)
                for msg, group_list in sorted(grouped.items(), key=lambda x: len(x[1]), reverse=True):
                    result.add_error(f"GRAPHICS_SYNC {len(group_list)}√ó {msg}")
                result.add_recommendation("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ payload ‚Üî apply*Updates –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤")
            
        except Exception as e:
            result.add_error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ graphics –ª–æ–≥–æ–≤: {e}")
        
        return result
    
    def _analyze_ibl_logs(self) -> LogAnalysisResult:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç IBL –ª–æ–≥–∏"""
        result = LogAnalysisResult()
        
        ibl_dir = self.logs_dir / "ibl"
        if not ibl_dir.exists():
            result.add_warning("–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è IBL –ª–æ–≥–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return result
        
        ibl_logs = sorted(ibl_dir.glob("ibl_signals_*.log"), key=lambda p: p.stat().st_mtime, reverse=True)
        
        if not ibl_logs:
            result.add_warning("–ù–µ—Ç IBL –ª–æ–≥–æ–≤")
            return result
        
        latest_ibl = ibl_logs[0]
        
        try:
            with open(latest_ibl, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            errors = [line for line in lines if 'ERROR' in line or 'CRITICAL' in line]
            warnings = [line for line in lines if 'WARN' in line]
            success = [line for line in lines if 'SUCCESS' in line or 'LOADED successfully' in line]
            
            result.add_metric('ibl_total_events', len(lines))
            result.add_metric('ibl_errors', len(errors))
            result.add_metric('ibl_warnings', len(warnings))
            result.add_metric('ibl_success', len(success))
            
            if errors:
                # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
                norm = defaultdict(list)
                for line in errors:
                    msg = re.sub(r'\s+', ' ', line.strip())
                    norm[msg].append(line)
                result.add_error(f"IBL –æ—à–∏–±–∫–∏: {len(errors)} (—É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: {len(norm)})")
                for msg, lines_same in sorted(norm.items(), key=lambda x: len(x[1]), reverse=True):
                    result.add_error(f"[IBL] {len(lines_same)}√ó {msg}")
                result.add_recommendation("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç–∏ –∫ HDR / –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞ / –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤")
            
            if success:
                result.add_info(f"IBL —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω ({len(success)} —Å–æ–±—ã—Ç–∏–π)")
            
        except Exception as e:
            result.add_error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ IBL –ª–æ–≥–æ–≤: {e}")
        
        return result
    
    def _analyze_event_logs(self) -> LogAnalysisResult:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ª–æ–≥–∏ —Å–æ–±—ã—Ç–∏–π Python‚ÜîQML"""
        result = LogAnalysisResult()
        
        # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —Å–æ–±—ã—Ç–∏—è —á–µ—Ä–µ–∑ EventLogger
        try:
            from src.common.event_logger import get_event_logger
            
            event_logger = get_event_logger()
            analysis = event_logger.analyze_sync()
            
            total = analysis.get('total_signals', 0)
            synced = analysis.get('synced', 0)
            missing = analysis.get('missing_qml', 0)
            
            result.add_metric('event_total', total)
            result.add_metric('event_synced', synced)
            result.add_metric('event_missing', missing)
            
            if total > 0:
                sync_rate = (synced / total) * 100
                result.add_metric('event_sync_rate', sync_rate)
                
                if sync_rate >= 95:
                    result.add_info(f"Python‚ÜîQML —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è: {sync_rate:.1f}% (–æ—Ç–ª–∏—á–Ω–æ)")
                elif sync_rate >= 80:
                    result.add_warning(f"Python‚ÜîQML —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è: {sync_rate:.1f}%")
                else:
                    result.add_error(f"Python‚ÜîQML —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è: {sync_rate:.1f}% (–∫—Ä–∏—Ç–∏—á–Ω–æ)")
            
                if missing > 0:
                    result.add_warning(f"–ü—Ä–æ–ø—É—â–µ–Ω–æ QML —Å–æ–±—ã—Ç–∏–π: {missing}")
                    # –î–µ—Ç–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –µ—Å–ª–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω
                    missing_list = analysis.get('missing_event_names') or []
                    if missing_list:
                        for name in missing_list[:10]:
                            result.add_error(f"MISSING_QML_SIGNAL {name}")
                        if len(missing_list) > 10:
                            result.add_warning(f"... –µ—â—ë {len(missing_list)-10} –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ —Å–∫—Ä—ã—Ç–æ")
                    result.add_recommendation("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ QML Connections –∏–ª–∏ –∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–æ–≤")
            else:
                result.add_info("–°–æ–±—ã—Ç–∏–π Python‚ÜîQML –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ (–≤–æ–∑–º–æ–∂–Ω–æ, –Ω–µ –±—ã–ª–æ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏)")
            
        except ImportError:
            result.add_warning("EventLogger –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω - –ø—Ä–æ–ø—É—â–µ–Ω –∞–Ω–∞–ª–∏–∑ —Å–æ–±—ã—Ç–∏–π")
        except Exception as e:
            result.add_error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å–æ–±—ã—Ç–∏–π: {e}")
        
        return result
    
    def _generate_summary(self) -> LogAnalysisResult:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ–±—â–∏–π summary"""
        summary = LogAnalysisResult()
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –æ—à–∏–±–∫–∏ –∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
        all_errors = []
        all_warnings = []
        all_metrics = {}
        all_recommendations = []
        
        for category, result in self.results.items():
            if category == 'summary':
                continue
            
            all_errors.extend(result.errors)
            all_warnings.extend(result.warnings)
            all_metrics.update({f"{category}_{k}": v for k, v in result.metrics.items()})
            all_recommendations.extend(result.recommendations)
        
        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        summary.add_metric('total_errors', len(all_errors))
        summary.add_metric('total_warnings', len(all_warnings))
        summary.add_metric('total_recommendations', len(all_recommendations))
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–±—â–∏–π —Å—Ç–∞—Ç—É—Å
        if all_errors:
            summary.status = "error"
            summary.add_error(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º: {len(all_errors)}")
        elif all_warnings:
            summary.status = "warning"
            summary.add_warning(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π: {len(all_warnings)}")
        else:
            summary.status = "ok"
            summary.add_info("–í—Å–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–π–¥–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ —Å–æ–±—Ä–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        for error in all_errors:
            if error not in summary.errors:
                summary.errors.append(error)
        
        for warning in all_warnings:
            if warning not in summary.warnings:
                summary.warnings.append(warning)
        
        for rec in all_recommendations:
            if rec not in summary.recommendations:
                summary.recommendations.append(rec)
        
        summary.metrics.update(all_metrics)
        
        return summary
    
    def print_results(self):
        """–í—ã–≤–æ–¥–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –≤ –∫–æ–Ω—Å–æ–ª—å"""
        print("\n" + "="*70)
        print("üìä –ö–û–ú–ü–õ–ï–ö–°–ù–´–ô –ê–ù–ê–õ–ò–ó –õ–û–ì–û–í")
        print("="*70)
        
        for category, result in self.results.items():
            if category == 'summary':
                continue
            
            print(f"\nüìÅ {category.upper()}")
            print("-"*70)
            
            # –ú–µ—Ç—Ä–∏–∫–∏
            if result.metrics:
                print("\n–ú–µ—Ç—Ä–∏–∫–∏:")
                for name, value in result.metrics.items():
                    print(f"  ‚Ä¢ {name}: {value}")
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            if result.info:
                print("\n‚ÑπÔ∏è  –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:")
                for info in result.info:
                    print(f"  {info}")
            
            # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
            if result.warnings:
                print("\n‚ö†Ô∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è:")
                for warning in result.warnings:
                    print(f"  {warning}")
            
            # –û—à–∏–±–∫–∏ (—É–∂–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏/–∞–≥—Ä–µ–≥–∞—Ü–∏–∏)
            if result.errors:
                print("\n‚ùå –û—à–∏–±–∫–∏ (–∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ / –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ):")
                for error in result.errors:
                    print(f"  {error}")
        
        # Summary
        if 'summary' in self.results:
            summary = self.results['summary']
            
            print("\n" + "="*70)
            print("üìã –ò–¢–û–ì–ò")
            print("="*70)
            
            status_icon = {
                'ok': '‚úÖ',
                'warning': '‚ö†Ô∏è',
                'error': '‚ùå'
            }.get(summary.status, '‚ùì')
            
            print(f"\n–°—Ç–∞—Ç—É—Å: {status_icon} {summary.status.upper()}")
            print(f"–û—à–∏–±–æ–∫ (–≤–∫–ª—é—á–∞—è –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ): {len(summary.errors)}")
            print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π: {len(summary.warnings)}")
            
            if summary.recommendations:
                print("\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
                for i, rec in enumerate(summary.recommendations, 1):
                    print(f"  {i}. {rec}")
        
        print("\n" + "="*70 + "\n")


# ============================================================================
# –≠–ö–°–ü–û–†–¢–ù–´–ï –§–£–ù–ö–¶–ò–ò –î–õ–Ø APP.PY
# ============================================================================

def run_full_diagnostics(logs_dir: Path = Path("logs")) -> bool:
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—É—é –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É –≤—Å–µ—Ö –ª–æ–≥–æ–≤
    
    Args:
        logs_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –ª–æ–≥–∞–º–∏
    
    Returns:
        True –µ—Å–ª–∏ –ø—Ä–æ–±–ª–µ–º –Ω–µ—Ç, False –µ—Å–ª–∏ –µ—Å—Ç—å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã
    """
    analyzer = UnifiedLogAnalyzer(logs_dir)
    results = analyzer.analyze_all()
    analyzer.print_results()
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º True —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫
    return results.get('summary', LogAnalysisResult()).status != "error"


def quick_diagnostics(logs_dir: Path = Path("logs")) -> Dict[str, any]:
    """
    –ë—ã—Å—Ç—Ä–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ - —Ç–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    
    Returns:
        Dict —Å –∫–ª—é—á–µ–≤—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
    """
    analyzer = UnifiedLogAnalyzer(logs_dir)
    results = analyzer.analyze_all()
    
    summary = results.get('summary', LogAnalysisResult())
    
    return {
        'status': summary.status,
        'errors': len(summary.errors),
        'warnings': len(summary.warnings),
        'recommendations': len(summary.recommendations),
        'metrics': summary.metrics
    }
