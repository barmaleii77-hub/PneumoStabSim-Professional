# -*- coding: utf-8 -*-
"""
–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ª–æ–≥–æ–≤ PneumoStabSim
–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ —Ç–∏–ø—ã –∞–Ω–∞–ª–∏–∑–æ–≤ –≤ –µ–¥–∏–Ω—É—é —Å–∏—Å—Ç–µ–º—É
"""

from pathlib import Path
from typing import Dict, List
from datetime import datetime
import json
import re
from collections import defaultdict, Counter


class LogAnalysisResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –ª–æ–≥–æ–≤"""

    def __init__(self):
        self.errors: List[str] = []
        self.warnings: List[str] = []
        self.info: List[str] = []
        self.metrics: Dict[str, float] = {}
        self.recommendations: List[str] = []
        self.status: str = "unknown"  # ok, warning, error

    def is_ok(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –≤—Å—ë –ª–∏ –≤ –ø–æ—Ä—è–¥–∫–µ"""
        return len(self.errors) == 0 and self.status != "error"

    def add_error(self, message: str):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –æ—à–∏–±–∫—É"""
        self.errors.append(message)
        self.status = "error"

    def add_warning(self, message: str):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ"""
        self.warnings.append(message)
        if self.status != "error":
            self.status = "warning"

    def add_info(self, message: str):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é"""
        self.info.append(message)
        if self.status == "unknown":
            self.status = "ok"

    def add_metric(self, name: str, value: float):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –º–µ—Ç—Ä–∏–∫—É"""
        self.metrics[name] = value

    def add_recommendation(self, message: str):
        """–î–æ–±–∞–≤–ª—è–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é"""
        self.recommendations.append(message)

    # --- NEW helpers for structured errors ---
    def add_collapsed_errors(self, errors: List[str]):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –Ω–∞–±–æ—Ä –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –æ—à–∏–±–æ–∫ (—É–Ω–∏–∫–∞–ª–∏–∑–∏—Ä—É—è –ø–æ —Å–æ–æ–±—â–µ–Ω–∏—é)."""
        for e in errors:
            self.add_error(e)


class UnifiedLogAnalyzer:
    """–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ –ª–æ–≥–æ–≤"""

    def __init__(self, logs_dir: Path = Path("logs")):
        self.logs_dir = logs_dir
        self.results: Dict[str, LogAnalysisResult] = {}

    def analyze_all(self) -> Dict[str, LogAnalysisResult]:
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö –ª–æ–≥–æ–≤"""

        # –û—Å–Ω–æ–≤–Ω–æ–π –ª–æ–≥
        self.results["main"] = self._analyze_main_log()

        # Graphics –ª–æ–≥–∏
        self.results["graphics"] = self._analyze_graphics_logs()

        # IBL –ª–æ–≥–∏
        self.results["ibl"] = self._analyze_ibl_logs()

        # Event –ª–æ–≥–∏ (Python‚ÜîQML)
        self.results["events"] = self._analyze_event_logs()

        # –û–±—â–∏–π —Å—Ç–∞—Ç—É—Å
        self.results["summary"] = self._generate_summary()

        return self.results

    def _analyze_main_log(self) -> LogAnalysisResult:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ—Å–Ω–æ–≤–Ω–æ–π –ª–æ–≥ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
        result = LogAnalysisResult()

        run_log = self.logs_dir / "run.log"
        if not run_log.exists():
            result.add_error("run.log –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return result

        try:
            with open(run_log, "r", encoding="utf-8") as f:
                lines = f.readlines()

            errors = [line for line in lines if "ERROR" in line or "CRITICAL" in line]
            warnings = [line for line in lines if "WARNING" in line]

            result.add_metric("total_lines", len(lines))
            result.add_metric("errors", len(errors))
            result.add_metric("warnings", len(warnings))

            if errors:
                # –ü–æ–ª–Ω—ã–π —Ä–∞–∑–±–æ—Ä –æ—à–∏–±–æ–∫ —Å –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–æ–π –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –±–µ–∑ —Ç–∞–π–º—Å—Ç–µ–º–ø–æ–≤
                norm_errors: Dict[str, List[str]] = defaultdict(list)
                ts_re = re.compile(r"^\s*\d{4}-\d{2}-\d{2}[^ ]*\s+")
                for line in errors:
                    base = ts_re.sub("", line).strip()
                    # –£—Ä–µ–∑–∞–µ–º –ø—É—Ç—å –≤–Ω—É—Ç—Ä–∏ traceback —Å—Ç—Ä–æ–∫ –¥–æ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞ –¥–ª—è –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
                    base_short = re.sub(
                        r'File "([^"]+)"',
                        lambda m: f"File '{Path(m.group(1)).name}'",
                        base,
                    )
                    norm_errors[base_short].append(line.strip())

                # –î–æ–±–∞–≤–ª—è–µ–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å—Ç—Ä–æ–∫—É
                result.add_error(
                    f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(errors)} –æ—à–∏–±–æ–∫ –≤ run.log (—É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: {len(norm_errors)})"
                )
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –≤—Ö–æ–∂–¥–µ–Ω–∏–π
                for msg, lines_same in sorted(
                    norm_errors.items(), key=lambda x: len(x[1]), reverse=True
                ):
                    count = len(lines_same)
                    prefix = (
                        "CRITICAL" if "CRITICAL" in msg or "FATAL" in msg else "ERROR"
                    )
                    result.add_error(f"[{prefix}] {count}√ó {msg}")
                # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–æ—Ç–∫–∏–π —Å–æ–≤–µ—Ç –µ—Å–ª–∏ –º–Ω–æ–≥–æ —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤
                if len(norm_errors) > 5:
                    result.add_recommendation(
                        "–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –æ—à–∏–±–æ–∫ ‚Äî –Ω–∞—á–Ω–∏—Ç–µ —Å –ø–µ—Ä–≤–æ–π –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –ø–æ–≤—Ç–æ—Ä–æ–≤."
                    )

            if warnings:
                result.add_warning(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(warnings)} –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π")
                if len(warnings) > 10:
                    result.add_recommendation(
                        "–ú–Ω–æ–≥–æ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π - –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é"
                    )

            if not errors and not warnings:
                result.add_info("–û—Å–Ω–æ–≤–Ω–æ–π –ª–æ–≥ —á–∏—Å—Ç—ã–π - –æ—à–∏–±–æ–∫ –Ω–µ—Ç")

            # –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–∏ —Ä–∞–±–æ—Ç—ã
            startup_time = None
            shutdown_time = None

            for line in lines:
                if "START RUN" in line:
                    match = re.search(r"\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}", line)
                    if match:
                        startup_time = match.group(0)
                elif "END RUN" in line:
                    match = re.search(r"\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}", line)
                    if match:
                        shutdown_time = match.group(0)

            if startup_time and shutdown_time:
                try:
                    start = datetime.fromisoformat(startup_time)
                    end = datetime.fromisoformat(shutdown_time)
                    duration = (end - start).total_seconds()
                    result.add_metric("runtime_seconds", duration)
                    result.add_info(f"–í—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã: {duration:.1f}s")
                except:
                    pass

        except Exception as e:
            result.add_error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ run.log: {e}")

        return result

    def _analyze_graphics_logs(self) -> LogAnalysisResult:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ª–æ–≥–∏ –≥—Ä–∞—Ñ–∏–∫–∏"""
        result = LogAnalysisResult()

        graphics_dir = self.logs_dir / "graphics"
        if not graphics_dir.exists():
            result.add_warning("–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è graphics –ª–æ–≥–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return result

        # –ù–∞—Ö–æ–¥–∏–º –ø–æ—Å–ª–µ–¥–Ω–∏–π session –ª–æ–≥
        session_logs = sorted(
            graphics_dir.glob("session_*.jsonl"),
            key=lambda p: p.stat().st_mtime,
            reverse=True,
        )

        if not session_logs:
            result.add_warning("–ù–µ—Ç session –ª–æ–≥–æ–≤ –≥—Ä–∞—Ñ–∏–∫–∏")
            return result

        latest_session = session_logs[0]

        try:
            events = []
            with open(latest_session, "r", encoding="utf-8") as f:
                for line in f:
                    if line.strip():
                        try:
                            events.append(json.loads(line))
                        except json.JSONDecodeError:
                            continue

            # –ê–Ω–∞–ª–∏–∑ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
            # –ë–µ—Ä–µ–º –∑–∞ –æ—Å–Ω–æ–≤—É —Ç–æ–ª—å–∫–æ –∏—Å—Ö–æ–¥–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (parameter_change)
            change_events = [
                e for e in events if e.get("event_type") == "parameter_change"
            ]
            update_success = [
                e
                for e in events
                if e.get("event_type") == "parameter_update"
                and e.get("applied_to_qml", False)
            ]
            total_events = len(change_events)
            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É—Å–ø–µ—à–Ω—ã—Ö –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–π –Ω–µ –º–æ–∂–µ—Ç –ø—Ä–µ–≤—ã—à–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–º–µ–Ω–µ–Ω–∏–π
            synced_events = min(len(update_success), total_events)
            failed_events = len(
                [
                    e
                    for e in events
                    if e.get("event_type") == "parameter_update" and e.get("error")
                ]
            )

            result.add_metric("graphics_total_events", total_events)
            result.add_metric("graphics_synced", synced_events)
            result.add_metric("graphics_failed", failed_events)

            if total_events > 0:
                sync_rate = (synced_events / total_events) * 100
                result.add_metric("graphics_sync_rate", sync_rate)

                if sync_rate >= 95:
                    result.add_info(
                        f"–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –≥—Ä–∞—Ñ–∏–∫–∏: {sync_rate:.1f}% (–æ—Ç–ª–∏—á–Ω–æ)"
                    )
                elif sync_rate >= 80:
                    result.add_warning(
                        f"–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –≥—Ä–∞—Ñ–∏–∫–∏: {sync_rate:.1f}% (–ø—Ä–∏–µ–º–ª–µ–º–æ)"
                    )
                    result.add_recommendation("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ QML —Ñ—É–Ω–∫—Ü–∏–∏ applyXxxUpdates()")
                else:
                    result.add_error(
                        f"–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –≥—Ä–∞—Ñ–∏–∫–∏: {sync_rate:.1f}% (–∫—Ä–∏—Ç–∏—á–Ω–æ –Ω–∏–∑–∫–∞—è)"
                    )
                    result.add_recommendation(
                        "–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ - –ø—Ä–æ–≤–µ—Ä—å—Ç–µ Python‚ÜîQML –º–æ—Å—Ç"
                    )

            # –ê–Ω–∞–ª–∏–∑ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
            # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å—á–∏—Ç–∞–µ–º –ø–æ –∏—Å—Ö–æ–¥–Ω—ã–º –∏–∑–º–µ–Ω–µ–Ω–∏—è–º
            categories = Counter(
                e.get("category", "unknown") for e in change_events if e.get("category")
            )
            if categories:
                result.add_info(f"–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π: {dict(categories)}")

            # –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –æ—à–∏–±–∫–∏ QML sync (error –ø–æ–ª—è)
            error_events = [e for e in events if e.get("error")]
            if error_events:
                grouped = defaultdict(list)
                for ev in error_events:
                    key = ev.get("error")
                    grouped[key].append(ev)
                for msg, group_list in sorted(
                    grouped.items(), key=lambda x: len(x[1]), reverse=True
                ):
                    result.add_error(f"GRAPHICS_SYNC {len(group_list)}√ó {msg}")
                result.add_recommendation(
                    "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ payload ‚Üî apply*Updates –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤"
                )

        except Exception as e:
            result.add_error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ graphics –ª–æ–≥–æ–≤: {e}")

        return result

    def _analyze_ibl_logs(self) -> LogAnalysisResult:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç IBL –ª–æ–≥–∏"""
        result = LogAnalysisResult()

        ibl_dir = self.logs_dir / "ibl"
        if not ibl_dir.exists():
            result.add_warning("–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è IBL –ª–æ–≥–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return result

        ibl_logs = sorted(
            ibl_dir.glob("ibl_signals_*.log"),
            key=lambda p: p.stat().st_mtime,
            reverse=True,
        )

        if not ibl_logs:
            result.add_warning("–ù–µ—Ç IBL –ª–æ–≥–æ–≤")
            return result

        latest_ibl = ibl_logs[0]

        try:
            with open(latest_ibl, "r", encoding="utf-8") as f:
                lines = [ln.strip() for ln in f.readlines() if ln.strip()]

            # –ë–∞–∑–æ–≤—ã–µ –ø–æ–¥—Å—á—ë—Ç—ã
            errors = [
                line for line in lines if " ERROR " in line or " CRITICAL " in line
            ]
            warnings = [line for line in lines if " WARN " in line]
            success = [
                line
                for line in lines
                if "SUCCESS" in line and "HDR probe LOADED successfully" in line
            ]

            result.add_metric("ibl_total_events", len(lines))
            result.add_metric("ibl_errors", len(errors))
            result.add_metric("ibl_warnings", len(warnings))
            result.add_metric("ibl_success", len(success))

            # –í–∞–ª–∏–¥–∞—Ü–∏—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π: Change ‚Üí Loading ‚Üí Ready (–∏–ª–∏ Error ‚Üí fallback ‚Üí Ready)
            re_change = re.compile(r"Primary source changed:\s+(.*)")
            re_status = re.compile(r"Texture status:\s+(\w+)\s+\|\s+source:\s+(.*)")
            re_success = re.compile(r"HDR probe LOADED successfully:\s+(.*)")
            re_switch = re.compile(r"Primary FAILED\s+‚Üí\s+switch to fallback:\s+(.*)")
            re_init = re.compile(
                r"IblProbeLoader initialized \| Primary:\s*(.*)\s*\|\s*Fallback:\s*(.*)"
            )

            state = "idle"
            current = None
            fallback = None
            saw_loading = False
            switched = False
            saw_ready = False
            last_status = None
            last_source = None
            sequence_errors: list[str] = []
            init_primary = None
            init_fallback = None

            def flush_state():
                nonlocal state, saw_loading, switched, saw_ready, current
                if state in ("changed", "loading") and not saw_ready:
                    sequence_errors.append(
                        f"–ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–ª—è {current or '?'} –Ω–µ –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å Ready"
                    )
                if state == "changed" and not saw_loading:
                    sequence_errors.append(
                        f"–î–ª—è {current or '?'} –Ω–µ –±—ã–ª–æ —Å—Ç–∞—Ç—É—Å–∞ Loading –ø–æ—Å–ª–µ —Å–º–µ–Ω—ã –∏—Å—Ç–æ—á–Ω–∏–∫–∞"
                    )
                # –°–±—Ä–æ—Å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                state = "idle"
                saw_loading = False
                switched = False
                saw_ready = False

            for ln in lines:
                m = re_init.search(ln)
                if m:
                    init_primary = (m.group(1) or "").strip()
                    init_fallback = (m.group(2) or "").strip()
                    if not init_primary or init_primary == "<empty>":
                        result.add_warning(
                            "IBL: –ø–µ—Ä–≤–∏—á–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ –Ω–µ –∑–∞–¥–∞–Ω –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏"
                        )
                    if not init_fallback or init_fallback == "<empty>":
                        result.add_warning(
                            "IBL: fallback –∏—Å—Ç–æ—á–Ω–∏–∫ –Ω–µ –∑–∞–¥–∞–Ω –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏"
                        )
                    continue

                m = re_change.search(ln)
                if m:
                    # –ó–∞–≤–µ—Ä—à–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å
                    flush_state()
                    current = m.group(1).strip()
                    state = "changed"
                    continue

                m = re_status.search(ln)
                if m:
                    last_status = m.group(1)
                    last_source = m.group(2).strip()
                    if last_status == "Loading" and state in ("changed", "loading"):
                        saw_loading = True
                        state = "loading"
                    elif last_status == "Ready":
                        saw_ready = True
                        state = "ready"
                    elif last_status == "Error":
                        # –û—à–∏–±–∫–∞ –ø–µ—Ä–≤–∏—á–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –¥–æ–ª–∂–Ω–∞ —Å–æ–ø—Ä–æ–≤–æ–∂–¥–∞—Ç—å—Å—è switch ‚Üí fallback
                        if not switched:
                            # –ü–æ–¥–æ–∂–¥—ë–º switch-–∑–∞–ø–∏—Å—å; –µ—Å–ª–∏ –µ—ë –Ω–µ –±—É–¥–µ—Ç –¥–æ —Å–ª–µ–¥—É—é—â–µ–π —Å–º–µ–Ω—ã, –æ—Ç–º–µ—Ç–∏–º –æ—à–∏–±–∫—É –ø—Ä–∏ flush
                            pass
                        state = "error"
                    continue

                m = re_switch.search(ln)
                if m:
                    switched = True
                    fallback = m.group(1).strip()
                    state = "changed"  # –æ–∂–∏–¥–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –Ω–æ–≤–æ–≥–æ (fallback)
                    continue

                m = re_success.search(ln)
                if m:
                    last_source = m.group(1).strip()
                    saw_ready = True
                    state = "ready"
                    continue

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ö–≤–æ—Å—Ç–∞
            flush_state()

            # –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
            result.add_metric("ibl_sequence_ok", 1.0 if not sequence_errors else 0.0)
            if last_status:
                result.add_metric("ibl_last_status", 1 if last_status == "Ready" else 0)
            if last_source:
                try:
                    result.add_info(f"–ü–æ—Å–ª–µ–¥–Ω–∏–π –∏—Å—Ç–æ—á–Ω–∏–∫ IBL: {last_source}")
                except Exception:
                    pass

            # –°–∏–≥–Ω–∞–ª—ã –æ –Ω–µ–±–µ–∑–æ–ø–∞—Å–Ω—ã—Ö –¥–µ—Ñ–æ–ª—Ç–∞—Ö/–Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è—Ö
            if init_primary and init_primary.endswith(
                ("studio.hdr", "studio_small_09_2k.hdr")
            ):
                result.add_warning(
                    "IBL: –æ–±–Ω–∞—Ä—É–∂–µ–Ω –≤–æ–∑–º–æ–∂–Ω—ã–π –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π HDR –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ ‚Äî –ø—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é UI –Ω–∞—Å—Ç—Ä–æ–µ–∫"
                )

            if sequence_errors:
                for err in sequence_errors:
                    result.add_error(f"IBL sequence: {err}")
                if not success:
                    result.add_recommendation(
                        "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –ø–æ—Å–ª–µ –≤—ã–±–æ—Ä–∞ HDR –∏–¥—ë—Ç Loading ‚Üí Ready; –ø—Ä–∏ Error –¥–æ–ª–∂–µ–Ω —Å—Ä–∞–±–æ—Ç–∞—Ç—å fallback"
                    )

            if errors:
                # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
                norm = defaultdict(list)
                for line in errors:
                    msg = re.sub(r"\s+", " ", line.strip())
                    norm[msg].append(line)
                result.add_error(f"IBL –æ—à–∏–±–∫–∏: {len(errors)} (—É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: {len(norm)})")
                for msg, lines_same in sorted(
                    norm.items(), key=lambda x: len(x[1]), reverse=True
                ):
                    result.add_error(f"[IBL] {len(lines_same)}√ó {msg}")
                result.add_recommendation(
                    "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç–∏ –∫ HDR / –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞ / –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤"
                )

            if success:
                result.add_info(f"IBL —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω ({len(success)} —Å–æ–±—ã—Ç–∏–π)")

        except Exception as e:
            result.add_error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ IBL –ª–æ–≥–æ–≤: {e}")

        return result

    def _analyze_event_logs(self) -> LogAnalysisResult:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ª–æ–≥–∏ —Å–æ–±—ã—Ç–∏–π Python‚ÜîQML"""
        result = LogAnalysisResult()

        # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —Å–æ–±—ã—Ç–∏—è —á–µ—Ä–µ–∑ EventLogger
        try:
            from src.common.event_logger import get_event_logger

            event_logger = get_event_logger()
            analysis = event_logger.analyze_sync()

            total = analysis.get("total_signals", 0)
            synced = analysis.get("synced", 0)
            missing = analysis.get("missing_qml", 0)

            result.add_metric("event_total", total)
            result.add_metric("event_synced", synced)
            result.add_metric("event_missing", missing)

            if total > 0:
                sync_rate = (synced / total) * 100
                result.add_metric("event_sync_rate", sync_rate)

                if sync_rate >= 95:
                    result.add_info(
                        f"Python‚ÜîQML —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è: {sync_rate:.1f}% (–æ—Ç–ª–∏—á–Ω–æ)"
                    )
                elif sync_rate >= 80:
                    result.add_warning(f"Python‚ÜîQML —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è: {sync_rate:.1f}%")
                else:
                    result.add_error(
                        f"Python‚ÜîQML —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è: {sync_rate:.1f}% (–∫—Ä–∏—Ç–∏—á–Ω–æ)"
                    )

                if missing > 0:
                    result.add_warning(f"–ü—Ä–æ–ø—É—â–µ–Ω–æ QML —Å–æ–±—ã—Ç–∏–π: {missing}")
                    # –î–µ—Ç–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –µ—Å–ª–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω
                    missing_list = analysis.get("missing_event_names") or []
                    if missing_list:
                        for name in missing_list[:10]:
                            result.add_error(f"MISSING_QML_SIGNAL {name}")
                        if len(missing_list) > 10:
                            result.add_warning(
                                f"... –µ—â—ë {len(missing_list)-10} –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ —Å–∫—Ä—ã—Ç–æ"
                            )
                    result.add_recommendation(
                        "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ QML Connections –∏–ª–∏ –∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–æ–≤"
                    )
            else:
                result.add_info(
                    "–°–æ–±—ã—Ç–∏–π Python‚ÜîQML –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ (–≤–æ–∑–º–æ–∂–Ω–æ, –Ω–µ –±—ã–ª–æ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏)"
                )

        except ImportError:
            result.add_warning("EventLogger –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω - –ø—Ä–æ–ø—É—â–µ–Ω –∞–Ω–∞–ª–∏–∑ —Å–æ–±—ã—Ç–∏–π")
        except Exception as e:
            result.add_error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å–æ–±—ã—Ç–∏–π: {e}")

        return result

    def _generate_summary(self) -> LogAnalysisResult:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ–±—â–∏–π summary"""
        summary = LogAnalysisResult()

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –æ—à–∏–±–∫–∏ –∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
        all_errors = []
        all_warnings = []
        all_metrics = {}
        all_recommendations = []

        for category, result in self.results.items():
            if category == "summary":
                continue

            all_errors.extend(result.errors)
            all_warnings.extend(result.warnings)
            all_metrics.update(
                {f"{category}_{k}": v for k, v in result.metrics.items()}
            )
            all_recommendations.extend(result.recommendations)

        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        summary.add_metric("total_errors", len(all_errors))
        summary.add_metric("total_warnings", len(all_warnings))
        summary.add_metric("total_recommendations", len(all_recommendations))

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–±—â–∏–π —Å—Ç–∞—Ç—É—Å
        if all_errors:
            summary.status = "error"
            summary.add_error(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º: {len(all_errors)}")
        elif all_warnings:
            summary.status = "warning"
            summary.add_warning(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π: {len(all_warnings)}")
        else:
            summary.status = "ok"
            summary.add_info("–í—Å–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–π–¥–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ —Å–æ–±—Ä–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        for error in all_errors:
            if error not in summary.errors:
                summary.errors.append(error)

        for warning in all_warnings:
            if warning not in summary.warnings:
                summary.warnings.append(warning)

        for rec in all_recommendations:
            if rec not in summary.recommendations:
                summary.recommendations.append(rec)

        summary.metrics.update(all_metrics)

        return summary

    def print_results(self):
        """–í—ã–≤–æ–¥–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –≤ –∫–æ–Ω—Å–æ–ª—å"""
        print("\n" + "=" * 70)
        print("üìä –ö–û–ú–ü–õ–ï–ö–°–ù–´–ô –ê–ù–ê–õ–ò–ó –õ–û–ì–û–í")
        print("=" * 70)

        for category, result in self.results.items():
            if category == "summary":
                continue

            print(f"\nüìÅ {category.upper()}")
            print("-" * 70)

            # –ú–µ—Ç—Ä–∏–∫–∏
            if result.metrics:
                print("\n–ú–µ—Ç—Ä–∏–∫–∏:")
                for name, value in result.metrics.items():
                    print(f"  ‚Ä¢ {name}: {value}")

            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            if result.info:
                print("\n‚ÑπÔ∏è  –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:")
                for info in result.info:
                    print(f"  {info}")

            # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
            if result.warnings:
                print("\n‚ö†Ô∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è:")
                for warning in result.warnings:
                    print(f"  {warning}")

            # –û—à–∏–±–∫–∏ (—É–∂–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏/–∞–≥—Ä–µ–≥–∞—Ü–∏–∏)
            if result.errors:
                print("\n‚ùå –û—à–∏–±–∫–∏ (–∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ / –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ):")
                for error in result.errors:
                    print(f"  {error}")

        # Summary
        if "summary" in self.results:
            summary = self.results["summary"]

            print("\n" + "=" * 70)
            print("üìã –ò–¢–û–ì–ò")
            print("=" * 70)

            status_icon = {"ok": "‚úÖ", "warning": "‚ö†Ô∏è", "error": "‚ùå"}.get(
                summary.status, "‚ùì"
            )

            print(f"\n–°—Ç–∞—Ç—É—Å: {status_icon} {summary.status.upper()}")
            print(f"–û—à–∏–±–æ–∫ (–≤–∫–ª—é—á–∞—è –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ): {len(summary.errors)}")
            print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π: {len(summary.warnings)}")

            if summary.recommendations:
                print("\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
                for i, rec in enumerate(summary.recommendations, 1):
                    print(f"  {i}. {rec}")

        print("\n" + "=" * 70 + "\n")


# ============================================================================
# –≠–ö–°–ü–û–†–¢–ù–´–ï –§–£–ù–ö–¶–ò–ò –î–õ–Ø APP.PY
# ============================================================================


def run_full_diagnostics(logs_dir: Path = Path("logs")) -> bool:
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—É—é –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É –≤—Å–µ—Ö –ª–æ–≥–æ–≤

    Args:
        logs_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –ª–æ–≥–∞–º–∏

    Returns:
        True –µ—Å–ª–∏ –ø—Ä–æ–±–ª–µ–º –Ω–µ—Ç, False –µ—Å–ª–∏ –µ—Å—Ç—å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã
    """
    analyzer = UnifiedLogAnalyzer(logs_dir)
    results = analyzer.analyze_all()
    analyzer.print_results()

    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º True —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫
    return results.get("summary", LogAnalysisResult()).status != "error"


def quick_diagnostics(logs_dir: Path = Path("logs")) -> Dict[str, any]:
    """
    –ë—ã—Å—Ç—Ä–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ - —Ç–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏

    Returns:
        Dict —Å –∫–ª—é—á–µ–≤—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
    """
    analyzer = UnifiedLogAnalyzer(logs_dir)
    results = analyzer.analyze_all()

    summary = results.get("summary", LogAnalysisResult())

    return {
        "status": summary.status,
        "errors": len(summary.errors),
        "warnings": len(summary.warnings),
        "recommendations": len(summary.recommendations),
        "metrics": summary.metrics,
    }
